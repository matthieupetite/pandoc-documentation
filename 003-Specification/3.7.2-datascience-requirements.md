# Datascience landing zone requirements

The table below outlines the criteria for implementing the datascience landing, categorized as follows:

- Data Requirements
- Security and Compliance
- Performance and Scalability
- Data Processing and Storage
- Integration Requirements
- Budget and Cost Management
- Disaster Recovery and High Availability
- Operational Management
- Development and Deployment (DevOps)

Identifying those requirements is crucial because it will influence all the implementation decisions.

## Data Requirements

| ID                    | Title                      | Description                                                                   |
| :-------------------- | :------------------------- | :---------------------------------------------------------------------------- |
| OCB-AZ-DATA-01 | Various Data Types  | The data platform must be capable of managing a wide variety of data types, such as audio files, database records, and JSON data. |
| OCB-AZ-DATA-02 | Primary Data Source | Snowflake will be used as the main data source, acting as the single source of truth, with daily data ingestion handled by the Data Factory team via Talend. |
| OCB-AZ-DATA-03 | Data Retention      | Data must be archived and anonymized after three years to comply with regulatory requirements. |

: Datascience platform data requirements

## Security and compliance

| ID                    | Title                      | Description                                                                   |
| :-------------------- | :------------------------- | :---------------------------------------------------------------------------- |
| OCB-AZ-DATA-04 | Regulatory compliance   | The data platform must adhere to industry-specific regulations and internal security policies, including GDPR compliance. |
| OCB-AZ-DATA-05 | Access Control          | The data platform must Restrict access to internal company employees only, with robust IAM policies.                      |
| OCB-AZ-DATA-06 | Encryption              | The data platform must implement data encryption at rest and in transit, with strong key management practices.            |
| OCB-AZ-DATA-07 | Policy Based management | A set of policy must be deployed to handle the platform security and governance process.                                  |

: Datascience platform security and compliance requirements

## Performance and scalability

| ID             | Title          | Description                                                                                     |
| :-------------------- | :------------------------- | :----------------------------------------------------------------------------|
| OCB-AZ-DATA-08 | Scalability    | The architecture must be scalable to handle increasing data volumes and support future growth   |
| OCB-AZ-DATA-09 | Data Ingestion | Daily batch processing is sufficient, with occasional requirements for real-time data streaming |

: Datascience platform performance and scalability requirements

## Data processing and storage

| ID                    | Title                      | Description                                                                   |
| :-------------------- | :------------------------- | :---------------------------------------------------------------------------- |
| OCB-AZ-DATA-10 | Processing        | The architecture must support both real-time processing (e.g., speech-to-text) and batch processing (e.g., daily ingestion and transformation). |
| OCB-AZ-DATA-11 | Storage solutions | The primary storage solution must be Snowflake each time it is possible otherwise, Azure Storage Account V2 must be implemented.                |

: Datascience platform data processing and storage requirements

## Integration

<!-- La dessus on est hors des clous pour moi, pas de consomation direct de sources systems on premise, il faut preciser que les flux on premise sont https only -->
| ID                    | Title                      | Description                                                                   |
| :-------------------- | :------------------------- | :---------------------------------------------------------------------------- |
| OCB-AZ-DATA-12 | On Premises access | Rare use cases for integration with on-premises systems via existing connectivity landing zones using peering and private endpoints (for AS400 databases for instance or legacy systems not covered by the Snowflake daily copies) |

: Datascience platform integration requirements

## Finops
<!-- Il fournir un budget mensuel ou annuel a jour pour la sub hpr seulement-->
| ID                    | Title                      | Description                                                                   |
| :-------------------- | :------------------------- | :---------------------------------------------------------------------------- |
| OCB-AZ-DATA-12 | Budget Cap | A maximum of 50K€ TTC is defined to deployed all environments (hors production, pre-production, production)            |
| OCB-AZ-DATA-13 | Finops     | The project must implement the necessary tools and process to be able to follow the April best practices about Finops. |

: Datascience platform budget and cost management requirements

## Disaster recovery and high availability

| ID                    | Title                      | Description                                                                   |
| :-------------------- | :------------------------- | :---------------------------------------------------------------------------- |
| OCB-AZ-DATA-14        | Backup                     | The platform must implement regular backups of assets. Note: this is not a top priority due to the current low data volume and importance of the team and projects for the moment. It’ll however become more important in the upcoming years.|
| OCB-AZ-DATA-15        | High availability          | The architecture must be designed to implement high availability pattern at any level to avoid data loss and ensure continuous operation. Since the projects, such as APIs, will be integrated into customer-facing tools and applications, it is crucial to eliminate any potential downtime. |

: Datascience platform disaster recovery and high availability requirements

## Operational management

| ID                    | Title                      | Description                                                                   |
| :-------------------- | :------------------------- | :---------------------------------------------------------------------------- |
| OCB-AZ-DATA-16 | Monitoring         | The platform should use Azure Monitor, Log Analytics, and other Azure-native tools for operational management. A cloud Native monitoring toolchain must be deployed as a support for the operations. |
| OCB-AZ-DATA-17 | Automation         | Follow DevOps best practices with a focus on CI/CD pipelines for deployment and management is a must have.  |
| OCB-AZ-DATA-18 | Project Management | The project must be deploy by following the Agile principles, with an emphasis on iterative development and continuous integration |

: Datascience platform operational management requirements
